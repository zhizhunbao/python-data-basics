# Data Analysis Workflow

## Overview

The data analysis workflow is the core framework of data analysis projects, covering the complete process from data collection to result presentation. This module will detail the eight core steps of data analysis, helping you establish systematic analytical thinking and methods.

## Core Analysis Steps (8 Stages)

### Step 1: Data Collection

**Framework Used:** Pandas

```python
import pandas as pd

# Load California housing dataset from CSV file using Pandas
# This is the first step of data analysis: obtaining data sources
df = pd.read_csv('public/data/california_housing.csv')

# View basic data information
print(f"Data shape: {df.shape}")
print(df.head())
```

### Step 2: Data Overview

**Framework Used:** Pandas

```python
# Data overview: Check data shape, types, missing values, and other basic information
print(df.info())  # Data types and basic information
print(df.describe())  # Statistical summary
print(df.isnull().sum())  # Missing value statistics
```

### Step 3: Data Cleaning

**Framework Used:** Pandas

```python
# Data cleaning: Handle missing values, outliers, duplicates

# Handle missing values (delete or fill)
df = df.dropna()  # Delete rows containing missing values
# Or use: df.fillna(df.mean())  # Fill with mean values

# Handle outliers (remove records with negative house prices)
df = df[df['median_house_value'] > 0]

# Remove duplicates
df = df.drop_duplicates()

print(f"Data shape after cleaning: {df.shape}")
```

### Step 4: Feature Engineering

**Framework Used:** NumPy + Pandas + Scikit-learn

```python
import numpy as np

# Feature engineering: Create new features, data standardization

# Create new features
df['rooms_per_household'] = df['total_rooms'] / df['households']
df['bedrooms_per_room'] = df['total_bedrooms'] / df['total_rooms']
df['population_per_household'] = df['population'] / df['households']

# Data standardization
from sklearn.preprocessing import StandardScaler

numeric_features = ['median_income', 'housing_median_age', 'total_rooms']
scaler = StandardScaler()
df[numeric_features] = scaler.fit_transform(df[numeric_features])

print("Feature engineering completed")
```

### Step 5: Exploratory Analysis

**Framework Used:** Matplotlib + Seaborn + Pandas

```python
import matplotlib.pyplot as plt
import seaborn as sns

# Exploratory analysis: Distribution analysis, correlation analysis

# Set plotting style
sns.set_style("whitegrid")

# Create analysis charts
fig, axes = plt.subplots(2, 2, figsize=(15, 10))

# 1. House price distribution histogram
axes[0, 0].hist(df['median_house_value'], bins=50, alpha=0.7)
axes[0, 0].set_title('House Price Distribution')
axes[0, 0].set_xlabel('House Price')
axes[0, 0].set_ylabel('Frequency')

# 2. Scatter plot of income vs. house price
axes[0, 1].scatter(df['median_income'], df['median_house_value'], alpha=0.6)
axes[0, 1].set_title('Income vs. House Price')

# 3. Correlation heatmap
numeric_cols = ['median_house_value', 'median_income', 'total_rooms']
corr_matrix = df[numeric_cols].corr()
sns.heatmap(corr_matrix, annot=True, ax=axes[1, 0])

plt.tight_layout()
plt.show()
```

### Step 6: Data Visualization

**Framework Used:** Matplotlib + Pandas

```python
# Data visualization: Create professional charts and dashboards

fig, axes = plt.subplots(2, 2, figsize=(15, 10))

# 1. House price box plot
axes[0, 0].boxplot(df['median_house_value'])
axes[0, 0].set_title('House Price Box Plot')

# 2. Income distribution
axes[0, 1].hist(df['median_income'], bins=50, alpha=0.7)
axes[0, 1].set_title('Income Distribution')

# 3. Scatter plot
axes[1, 0].scatter(df['population'], df['median_house_value'], alpha=0.5)
axes[1, 0].set_title('Population vs. House Price')

plt.tight_layout()
plt.show()
```

### Step 7: Model Building

**Framework Used:** Scikit-learn + Pandas + NumPy

```python
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# Model building: Train house price prediction model

# Prepare features and target variable
feature_cols = ['median_income', 'housing_median_age', 'total_rooms']
X = df[feature_cols]
y = df['median_house_value']

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train linear regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Predict
y_pred = model.predict(X_test)

# Model evaluation
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

print(f"RMSE: {rmse:.2f}")
print(f"R² Score: {r2:.4f}")
```

### Step 8: Result Presentation

**Framework Used:** Matplotlib + Pandas

```python
# Result presentation: Model evaluation, report generation

fig, axes = plt.subplots(2, 2, figsize=(15, 10))

# 1. Predicted vs. actual values
axes[0, 0].scatter(y_test, y_pred, alpha=0.6)
axes[0, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
axes[0, 0].set_xlabel('Actual Values')
axes[0, 0].set_ylabel('Predicted Values')
axes[0, 0].set_title(f'Predicted vs. Actual (R² = {r2:.3f})')

# 2. Residual distribution
residuals = y_test - y_pred
axes[0, 1].hist(residuals, bins=30, alpha=0.7)
axes[0, 1].set_title('Residual Distribution')
axes[0, 1].axvline(x=0, color='r', linestyle='--')

plt.tight_layout()
plt.show()

# Generate summary report
print("\nData Analysis Project Summary Report")
print(f"Model Performance: RMSE={rmse:.2f}, R²={r2:.4f}")
```

---

*Mastering the complete data analysis workflow will lay a solid foundation for your data analysis career.*

## Core Functions

### Step 1: Data Collection Core Functions

| Function | Framework | Description |
|----------|-----------|-------------|
| `pd.read_csv()` | Pandas | Read data from CSV file |
| `pd.read_excel()` | Pandas | Read data from Excel file |
| `pd.read_json()` | Pandas | Read data from JSON file |
| `pd.read_sql()` | Pandas | Read data from SQL database |
| `df.head()` | Pandas | View first few rows of data |

### Step 2: Data Overview Core Functions

| Function | Framework | Description |
|----------|-----------|-------------|
| `df.info()` | Pandas | Display data types and basic information |
| `df.describe()` | Pandas | Display statistical summary |
| `df.shape` | Pandas | Get data dimensions |
| `df.columns` | Pandas | Get column names |
| `df.dtypes` | Pandas | Get data types |
| `df.isnull().sum()` | Pandas | Count missing values |
| `df.value_counts()` | Pandas | Count unique values |

### Step 3: Data Cleaning Core Functions

| Function | Framework | Description |
|----------|-----------|-------------|
| `df.dropna()` | Pandas | Drop missing values |
| `df.fillna()` | Pandas | Fill missing values |
| `df.drop_duplicates()` | Pandas | Drop duplicate values |
| `df.replace()` | Pandas | Replace values |
| `df.query()` | Pandas | Query and filter data |
| `df.drop()` | Pandas | Drop columns or rows |

### Step 4: Feature Engineering Core Functions

| Function | Framework | Description |
|----------|-----------|-------------|
| `StandardScaler()` | Scikit-learn | Standardize features |
| `MinMaxScaler()` | Scikit-learn | Min-max scaling |
| `LabelEncoder()` | Scikit-learn | Label encoding |
| `OneHotEncoder()` | Scikit-learn | One-hot encoding |
| `np.log()` | NumPy | Logarithmic transformation |
| `df.apply()` | Pandas | Apply custom function |

### Step 5: Exploratory Analysis Core Functions

| Function | Framework | Description |
|----------|-----------|-------------|
| `df.corr()` | Pandas | Calculate correlation matrix |
| `df.groupby()` | Pandas | Group and aggregate |
| `sns.heatmap()` | Seaborn | Draw heatmap |
| `sns.pairplot()` | Seaborn | Draw pairwise plots |
| `sns.distplot()` | Seaborn | Draw distribution plot |
| `df.pivot_table()` | Pandas | Create pivot table |

### Step 6: Data Visualization Core Functions

| Function | Framework | Description |
|----------|-----------|-------------|
| `plt.plot()` | Matplotlib | Draw line plot |
| `plt.scatter()` | Matplotlib | Draw scatter plot |
| `plt.hist()` | Matplotlib | Draw histogram |
| `plt.boxplot()` | Matplotlib | Draw box plot |
| `plt.bar()` | Matplotlib | Draw bar chart |
| `df.plot()` | Pandas | Pandas plotting interface |
| `plt.subplots()` | Matplotlib | Create subplots |

### Step 7: Model Building Core Functions

| Function | Framework | Description |
|----------|-----------|-------------|
| `train_test_split()` | Scikit-learn | Split training and test sets |
| `LinearRegression()` | Scikit-learn | Linear regression model |
| `RandomForestRegressor()` | Scikit-learn | Random forest regression |
| `LogisticRegression()` | Scikit-learn | Logistic regression |
| `model.fit()` | Scikit-learn | Train model |
| `model.predict()` | Scikit-learn | Model prediction |
| `cross_val_score()` | Scikit-learn | Cross-validation |

### Step 8: Result Presentation Core Functions

| Function | Framework | Description |
|----------|-----------|-------------|
| `mean_squared_error()` | Scikit-learn | Mean squared error |
| `r2_score()` | Scikit-learn | R² score |
| `accuracy_score()` | Scikit-learn | Accuracy score |
| `confusion_matrix()` | Scikit-learn | Confusion matrix |
| `classification_report()` | Scikit-learn | Classification report |
| `plt.savefig()` | Matplotlib | Save figure |
| `df.to_csv()` | Pandas | Export data |

---

*Mastering these core functions will greatly improve your data analysis efficiency and professional level.*
