# Pythonæ•°æ®å¤„ç†ä¸‰å‰‘å®¢

## åœºæ™¯1ï¼šAPIæ•°æ®äº¤æ¢ä¸è½»é‡å­˜å‚¨

**ä»»åŠ¡ï¼šæ¥æ”¶HTTP APIè¿”å›çš„JSONæ•°æ®å¹¶å¿«é€Ÿå¤„ç†ï¼ˆæ— éœ€å®‰è£…å¤–éƒ¨åº“ï¼‰**

> ğŸ’¡ **Python List/Dict = é€šç”¨å¯¹è±¡å¤„ç†ç¥å™¨ï¼Œä»€ä¹ˆéƒ½èƒ½è£…**  
> å°±åƒç‘å£«å†›åˆ€ï¼Œå¯ä»¥å¤„ç†å­—ç¬¦ä¸²ã€æ•°å­—ã€å­—å…¸ã€åˆ—è¡¨å„ç§æ•°æ®ç±»å‹ï¼Œçµæ´»é€šç”¨ï¼

###  List - Pythonæ ‡å‡†åº“ï¼Œæ— éœ€å®‰è£…ä¾èµ–

```python
import json
# ä»APIæ¥æ”¶JSONæ•°æ®
api_response = '''
[
    {"id": 1, "name": "å¼ ä¸‰", "score": 95},
    {"id": 2, "name": "æå››", "score": 87},
    {"id": 3, "name": "ç‹äº”", "score": 92}
]
'''
students = json.loads(api_response)  # ç›´æ¥è½¬ä¸ºPythonå­—å…¸åˆ—è¡¨

# å¿«é€Ÿç­›é€‰å’Œæ’åº
top_students = [s for s in students if s['score'] >= 90]
sorted_students = sorted(students, key=lambda x: x['score'], reverse=True)

print(f"ä¼˜ç§€å­¦ç”Ÿ: {[s['name'] for s in top_students]}")
# è¾“å‡ºç¤ºä¾‹: ä¼˜ç§€å­¦ç”Ÿ: ['å¼ ä¸‰', 'ç‹äº”']

# âœ… ä¼˜åŠ¿ï¼šé›¶ä¾èµ–ã€å¿«é€Ÿã€åŸç”ŸPythonå¯¹è±¡
# âœ… é€‚åˆï¼šAPIäº¤äº’ã€å¾®æœåŠ¡ã€Dockerå®¹å™¨ã€å†·å¯åŠ¨åœºæ™¯
```

###  Pandas - éœ€è¦é¢å¤–å®‰è£…ï¼Œå¤ªé‡

```python
import pandas as pd
df = pd.DataFrame(json.loads(api_response))
top = df[df['score'] >= 90]
print(top)
# åŠŸèƒ½å¼ºå¤§ï¼Œä½†éœ€è¦å®‰è£…pandasåº“ï¼ˆå‡ åMBï¼‰
# åœ¨åµŒå…¥å¼ç¯å¢ƒã€å®¹å™¨ã€å†·å¯åŠ¨åœºæ™¯ä¸‹æ˜¾å¾—è‡ƒè‚¿
```

###  NumPy - æ— æ³•å¤„ç†JSONå¯¹è±¡

```python
import numpy as np
# NumPyæ²¡æœ‰å­—ç¬¦ä¸²å’Œå­—å…¸æ”¯æŒ
# éœ€è¦å…ˆè½¬æ¢ä¸ºæ•°å€¼æ•°ç»„ï¼Œå¤±å»çµæ´»æ€§
```

**ä¼˜åŠ£è¯„é€‰ï¼š**
- **List**: â­â­â­â­â­ é›¶ä¾èµ–ã€è½»é‡çº§ã€å®Œç¾é€‚é…APIå’Œå¾®æœåŠ¡
- **Pandas**: â­â­â­ åŠŸèƒ½å¼ºå¤§ä½†é‡é‡çº§ï¼Œä¸é€‚åˆè½»é‡åœºæ™¯
- **NumPy**: â­ æ— æ³•å¤„ç†æ··åˆç±»å‹æ•°æ®

---

## åœºæ™¯2ï¼šå¤§è§„æ¨¡æ•°å€¼è®¡ç®—ä¸ç§‘å­¦è¿ç®—

**ä»»åŠ¡ï¼šå¤„ç†è‚¡ç¥¨ä»·æ ¼æ•°æ®ï¼Œè®¡ç®—æ”¶ç›Šç‡ã€æ³¢åŠ¨ç‡ï¼Œå¹¶è¿›è¡ŒçŸ©é˜µè®¡ç®—**

> ğŸ’¡ **NumPy = é«˜æ€§èƒ½æ•°ç»„åº“ï¼Œé¿å…é€å…ƒç´ å¾ªç¯**  
> å°±åƒç”¨â€œæ‰¹é‡æ“ä½œâ€æ›¿ä»£â€œä¸€è¡Œä¸€è¡Œå¤„ç†â€ï¼ŒNumPyåœ¨åº•å±‚ç”¨C/C++åŠ é€Ÿï¼Œæ€§èƒ½æå‡10-100å€ï¼

###  NumPy - å‘é‡åŒ–æ“ä½œï¼Œæ€§èƒ½æ— æ•Œ

```python
import numpy as np

# ç¤ºä¾‹ï¼š10å¤©çš„ä»·æ ¼æ•°æ®ï¼ˆå®é™…å¯ç”¨1000ä¸ªäº¤æ˜“æ—¥ï¼‰
sample_prices = np.array([100.0, 101.5, 99.8, 102.3, 101.0, 
                           103.2, 104.5, 103.8, 102.0, 105.2])

# æˆ–è€…ç”Ÿæˆ1000ä¸ªäº¤æ˜“æ—¥çš„æ¨¡æ‹Ÿæ•°æ®
prices = np.array([100 + np.cumsum(np.random.randn(1000) * 0.02)]).flatten()

# è®¡ç®—æ”¶ç›Šç‡ï¼ˆç”¨diffä¸€è¡Œæå®šï¼‰
returns = np.diff(prices) / prices[:-1] * 100

# ç»Ÿè®¡è¿ç®— - å‘é‡åŒ–ï¼Œæå¿«
mean_return = np.mean(returns)
volatility = np.std(returns) * np.sqrt(252)  # å¹´åŒ–æ³¢åŠ¨ç‡

# æ‰¹é‡æ¡ä»¶ç­›é€‰
positive_days = returns[returns > 0]
negative_days = returns[returns < 0]

print(f"å¹³å‡æ”¶ç›Šç‡: {mean_return:.3f}%")
print(f"å¹´åŒ–æ³¢åŠ¨ç‡: {volatility:.1f}%")
print(f"ä¸Šæ¶¨å¤©æ•°: {len(positive_days)}, ä¸‹è·Œå¤©æ•°: {len(negative_days)}")

# è¾“å‡ºç¤ºä¾‹:
# å¹³å‡æ”¶ç›Šç‡: 0.012%
# å¹´åŒ–æ³¢åŠ¨ç‡: 25.3%
# ä¸Šæ¶¨å¤©æ•°: 508, ä¸‹è·Œå¤©æ•°: 491
```

###  List - æ€§èƒ½ç¾éš¾ï¼Œå†…å­˜çˆ†ç‚¸

```python
# ç”¨Listå¤„ç†ï¼Œéœ€è¦éå†æ•´ä¸ªæ•°ç»„
import csv
prices = []
with open('prices.csv', 'r') as f:
    reader = csv.reader(f)
    for row in reader:
        prices.append(float(row[0]))

# è®¡ç®—æ”¶ç›Šç‡éœ€è¦æ‰‹åŠ¨éå†
returns = []
for i in range(len(prices) - 1):
    returns.append((prices[i+1] - prices[i]) / prices[i] * 100)

# è®¡ç®—å¹³å‡å€¼éœ€è¦å†éå†ä¸€æ¬¡
mean_return = sum(returns) / len(returns)  # è¶…æ…¢ï¼

# çŸ©é˜µè¿ç®—ï¼Ÿä¸å¯èƒ½çš„
```

###  Pandas - ä¸ºè¡¨æ ¼è®¾è®¡çš„ï¼Œå¢åŠ ä¸å¿…è¦çš„å¼€é”€

```python
import pandas as pd
import numpy as np

# Pandasåº•å±‚ä¾èµ–NumPyï¼Œä½†å¢åŠ äº†ç´¢å¼•ã€ç±»å‹ç­‰å¼€é”€
prices = pd.Series(np.random.randn(1000).cumsum())
returns = prices.pct_change() * 100
mean_return = returns.mean()  # æ¯”NumPyæ…¢

# çŸ©é˜µè®¡ç®—æ›´éº»çƒ¦
```

**ä¼˜åŠ£è¯„é€‰ï¼š**
- **NumPy**: â­â­â­â­â­ æ€§èƒ½æœ€ä½³ï¼Œæ•°å­¦è¿ç®—ä¸“ç²¾ï¼Œå‘é‡åŒ–æ“ä½œ
- **List**: â­â­ æ€§èƒ½æå·®ï¼Œéœ€è¦å¤šæ¬¡éå†
- **Pandas**: â­â­ ä¸ºè¡¨æ ¼è®¾è®¡ï¼Œæ•°å€¼è®¡ç®—ä¸å¦‚NumPyå¿«

---

## åœºæ™¯3ï¼šå¤æ‚å•†ä¸šæ•°æ®åˆ†æ

**ä»»åŠ¡ï¼šåˆ†æExcelé”€å”®æ•°æ®ï¼Œæ‰§è¡Œå¤šç»´åº¦åˆ†ç»„ã€é€è§†è¡¨ã€æ—¶é—´åºåˆ—åˆ†æ**

> ğŸ’¡ **Pandas = èƒ½ç¼–ç¨‹çš„Excel + åç«¯çš„SQL**  
> å¦‚æœä½ ç†Ÿæ‚‰Excelçš„æ•°æ®é€è§†è¡¨å’ŒSQLçš„GROUP BYï¼Œé‚£ä¹ˆPandaså°±æ˜¯ä½ çš„èœï¼

###  Pandas - å•†ä¸šåˆ†æç¥å™¨ï¼Œä¸å¯æ›¿ä»£

```python
import pandas as pd
# ä»Excelè¯»å–æ•°æ®
df = pd.DataFrame({
    'æ—¥æœŸ': ['2024-01-01', '2024-01-01', '2024-01-02', '2024-01-02', '2024-01-03'],
    'åœ°åŒº': ['åŒ—äº¬', 'ä¸Šæµ·', 'åŒ—äº¬', 'å¹¿å·', 'ä¸Šæµ·'],
    'é”€å”®é¢': [1000, 1500, 800, 1200, 2000],
    'äº§å“': ['ç¬”è®°æœ¬', 'é¼ æ ‡', 'é”®ç›˜', 'æ˜¾ç¤ºå™¨', 'ç¬”è®°æœ¬']
})

# âœ… å¤šç»´åº¦åˆ†ç»„åˆ†æ
result = df.groupby(['åœ°åŒº', 'äº§å“'])['é”€å”®é¢'].sum()
print("æŒ‰åœ°åŒºå’Œäº§å“åˆ†ç»„ç»Ÿè®¡:")
print(result)

# âœ… é€è§†è¡¨ - List/NumPyå®Œå…¨æ— æ³•å®ç°
pivot = df.pivot_table(values='é”€å”®é¢', index='åœ°åŒº', columns='äº§å“', aggfunc='sum')
print("\né€è§†è¡¨:")
print(pivot)

# âœ… æ—¶é—´åºåˆ—åˆ†æ
df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'])
daily = df.groupby(df['æ—¥æœŸ'].dt.date)['é”€å”®é¢'].sum()
print("\næ¯æ—¥é”€å”®é¢:")
print(daily)

# è¾“å‡ºç¤ºä¾‹:
# æŒ‰åœ°åŒºå’Œäº§å“åˆ†ç»„ç»Ÿè®¡:
# åœ°åŒº  äº§å“
# å¹¿å·  æ˜¾ç¤ºå™¨    1200
# ä¸Šæµ·  é¼ æ ‡      1500
#      ç¬”è®°æœ¬    2000
# åŒ—äº¬  é”®ç›˜       800
#      ç¬”è®°æœ¬    1000
#
# é€è§†è¡¨:
# äº§å“    ç¬”è®°æœ¬    é”®ç›˜    æ˜¾ç¤ºå™¨    é¼ æ ‡
# åœ°åŒº
# å¹¿å·      NaN   NaN  1200.0    NaN
# ä¸Šæµ·   2000.0   NaN     NaN  1500.0
# åŒ—äº¬   1000.0   800     NaN    NaN
#
# æ¯æ—¥é”€å”®é¢:
# æ—¥æœŸ
# 2024-01-01    2500
# 2024-01-02    2000
# 2024-01-03    2000
```

###  List - æ— æ³•å®ç°é€è§†è¡¨ç­‰é«˜çº§åŠŸèƒ½

```python
sales_data = [
    {'æ—¥æœŸ': '2024-01-01', 'region': 'åŒ—äº¬', 'amount': 1000, 'product': 'ç¬”è®°æœ¬'},
    {'æ—¥æœŸ': '2024-01-01', 'region': 'ä¸Šæµ·', 'amount': 1500, 'product': 'é¼ æ ‡'},
]
# ç®€å•åˆ†ç»„å‹‰å¼ºå¯ä»¥
grouped = {}
for record in sales_data:
    key = (record['region'], record['product'])
    grouped[key] = grouped.get(key, 0) + record['amount']
print(f"åˆ†ç»„ç»“æœ: {grouped}")  
# âŒ é€è§†è¡¨ï¼Ÿæ— æ³•å®ç°
# âŒ æ—¶é—´åºåˆ—ï¼Ÿæ— æ³•å®ç°
# âŒ ç»Ÿè®¡åˆ†æï¼Ÿéœ€è¦æ‰‹å·¥å®ç°
```

###  NumPy - æ²¡æœ‰è¡¨æ ¼å’Œåˆ†ç»„æ¦‚å¿µ

```python
import numpy as np
# NumPyåªèƒ½å¤„ç†åŒè´¨æ•°å€¼æ•°ç»„
# æ²¡æœ‰åˆ†ç»„ã€é€è§†è¡¨ç­‰åŠŸèƒ½
# å®Œå…¨ä¸é€‚åˆå•†ä¸šåˆ†æ
```

**ä¼˜åŠ£è¯„é€‰ï¼š**
- **Pandas**: â­â­â­â­â­ å•†ä¸šåˆ†æç¥å™¨ï¼Œé€è§†è¡¨ã€æ—¶é—´åºåˆ—ä¸å¯æ›¿ä»£
- **List**: â­â­ æ— æ³•å®ç°é€è§†è¡¨ç­‰é«˜çº§åŠŸèƒ½
- **NumPy**: â­ æ²¡æœ‰è¡¨æ ¼åˆ†æèƒ½åŠ›

### å†³ç­–æ ‘é€‰æ‹©

```mermaid
flowchart TD
  A[Pythonæ•°æ®å¤„ç†å·¥å…·é€‰æ‹©] --> B{æ˜¯å¦ä¸ºAPI/å¾®æœåŠ¡/è½»é‡åœºæ™¯}
  B -->|æ˜¯<br/>éœ€è¦é›¶ä¾èµ–| C[List<br/>é›¶ä¾èµ– å¿«é€Ÿ]
  B -->|å¦| D{æ•°æ®ç±»å‹}
  
  D -->|ä¸€è‡´<br/>çº¯æ•°å€¼æ•°ç»„| E{éœ€è¦é«˜æ€§èƒ½è®¡ç®—}
  D -->|ä¸ä¸€è‡´<br/>æ··åˆç±»å‹è¡¨æ ¼| F{éœ€è¦é€è§†è¡¨/åˆ†ç»„}
  
  E -->|æ˜¯<br/>çŸ©é˜µè¿ç®— ç§‘å­¦è®¡ç®—| G[NumPy<br/>å‘é‡åŒ–è¿ç®—]
  E -->|å¦<br/>ç®€å•å¤„ç†| C
  
  F -->|æ˜¯<br/>å•†ä¸šåˆ†æ| H[Pandas<br/>é€è§†è¡¨ æ—¶é—´åºåˆ—]
  F -->|å¦<br/>åŸºç¡€æ“ä½œ| C
  
  style A fill:#e1f5ff
  style C fill:#fff4e1
  style G fill:#ffe1f5
  style H fill:#e1ffe1
```

### ä¸‰å¤§æ¡†æ¶å¸¸ç”¨å‡½æ•°

| åŠŸèƒ½ | Listï¼ˆåŸç”ŸPythonï¼‰ | NumPy | Pandas |
|------|-------------------|-------|--------|
| **æ•°æ®è¯»å–** | `json.loads()` | `np.loadtxt()` | `pd.read_csv()` / `pd.read_excel()` |
| **è¿‡æ»¤ç­›é€‰** | `[x for x in lst if x > 5]` | `arr[arr > 5]` | `df[df['åˆ—'] > 5]` |
| **æ’åº** | `sorted(lst, key=lambda x: x)` | `np.sort(arr)` | `df.sort_values('åˆ—')` |
| **å»é‡** | `list(set(lst))` | `np.unique(arr)` | `df.drop_duplicates()` |
| **ç»Ÿè®¡è®¡ç®—** | `sum(lst)`, `len(lst)` | `np.sum()`, `np.mean()`, `np.std()` | `df.sum()`, `df.mean()`, `df.describe()` |
| **åˆ†ç»„èšåˆ** | æ‰‹åŠ¨å¾ªç¯ | âŒ æ—  | `df.groupby().agg()` |
| **é€è§†è¡¨** | âŒ æ— æ³•å®ç° | âŒ æ— æ³•å®ç° | `df.pivot_table()` |
| **æ—¶é—´åºåˆ—** | âŒ æ— æ³•å®ç° | `np.datetime64` | `pd.to_datetime()`, `resample()` |
| **æ¡ä»¶æ›´æ–°** | æ‰‹åŠ¨å¾ªç¯ | `np.where(condition, x, y)` | `df.loc[condition, 'åˆ—'] = value` |
| **å­—ç¬¦ä¸²å¤„ç†** | `str.split()`, `str.strip()` | âŒ æ—  | `df['åˆ—'].str.split()` |
| **åˆå¹¶è¿æ¥** | `list1 + list2` | `np.concatenate()` | `pd.concat()`, `pd.merge()` |
| **æ•°æ®é€è§†** | âŒ æ— æ³•å®ç° | âŒ æ— æ³•å®ç° | `df.pivot()` |

#### ğŸ¯ List å¸¸ç”¨å‡½æ•°é€ŸæŸ¥

```python
# åŸºç¡€æ“ä½œ
data = [1, 2, 3, 4, 5]
data.append(6)          # è¿½åŠ 
data.extend([7, 8])      # æ‰©å±•
data.insert(0, 0)        # æ’å…¥
data.pop()               # å¼¹å‡ºæœ€åä¸€ä¸ª

# ç­›é€‰è¿‡æ»¤
filtered = [x for x in data if x > 3]    # æ¡ä»¶ç­›é€‰
mapped = [x * 2 for x in data]           # æ˜ å°„å˜æ¢

# æ’åºå»é‡
sorted_data = sorted(data)               # æ’åº
unique_data = list(set(data))            # å»é‡
```

#### ğŸ”¢ NumPy å¸¸ç”¨å‡½æ•°é€ŸæŸ¥

```python
import numpy as np

arr = np.array([1, 2, 3, 4, 5])
matrix = np.array([[1, 2], [3, 4]])

# ======================================
# ğŸ“ åŸºç¡€æ•°ç»„æ“ä½œ
# ======================================
arr.reshape(5, 1)           # é‡å¡‘å½¢çŠ¶
arr.flatten()               # å±•å¹³
np.concatenate([arr1, arr2]) # æ‹¼æ¥
np.vstack([arr1, arr2])      # å‚ç›´å †å 
np.hstack([arr1, arr2])      # æ°´å¹³å †å 
arr.T                        # è½¬ç½®
np.split(arr, 3)            # åˆ†å‰²
np.array_split(arr, 3)      # ä¸ç­‰åˆ†å‰²

# ======================================
# ğŸ“Š ç»Ÿè®¡å‡½æ•°
# ======================================
np.sum(arr), np.mean(arr)   # æ±‚å’Œã€å¹³å‡å€¼
np.std(arr), np.var(arr)    # æ ‡å‡†å·®ã€æ–¹å·®
np.median(arr)              # ä¸­ä½æ•°
np.min(arr), np.max(arr)    # æœ€å€¼
np.percentile(arr, 75)      # åˆ†ä½æ•°
np.histogram(arr)           # ç›´æ–¹å›¾
np.unique(arr)              # å»é‡å¹¶æ’åº
np.bincount(arr)            # è®¡æ•°

# ======================================
# ğŸ”— åæ–¹å·®å’Œç›¸å…³æ€§
# ======================================
np.cov(matrix)              # åæ–¹å·®çŸ©é˜µ
np.corrcoef(matrix)         # ç›¸å…³ç³»æ•°çŸ©é˜µ

# ======================================
# ğŸ¯ æ¡ä»¶ç­›é€‰ï¼ˆå¸ƒå°”ç´¢å¼•ï¼‰
# ======================================
arr[arr > 3]                 # æ¡ä»¶ç­›é€‰
np.where(arr > 3, 1, 0)     # æ¡ä»¶èµ‹å€¼
np.where(arr > 3)           # è¿”å›ç´¢å¼•
np.select([arr < 3, arr > 7], [0, 1], 2)  # å¤šæ¡ä»¶

# ======================================
# ğŸ”¢ çº¿æ€§ä»£æ•° (np.linalg)
# ======================================
np.linalg.solve(A, b)       # è§£æ–¹ç¨‹ Ax=b
np.linalg.inv(matrix)       # çŸ©é˜µæ±‚é€†
np.linalg.pinv(matrix)     # ä¼ªé€†çŸ©é˜µ
np.linalg.eig(matrix)       # ç‰¹å¾å€¼/ç‰¹å¾å‘é‡
np.linalg.svd(matrix)       # SVDå¥‡å¼‚å€¼åˆ†è§£
np.linalg.qr(matrix)        # QRåˆ†è§£
np.linalg.det(matrix)       # è¡Œåˆ—å¼
np.linalg.matrix_rank(matrix) # çŸ©é˜µçš„ç§©
np.linalg.norm(arr)         # èŒƒæ•°
np.linalg.lstsq(A, b)       # æœ€å°äºŒä¹˜æ³•

# ======================================
# ğŸ“ˆ ç´¯ç§¯å‡½æ•°
# ======================================
np.cumsum(arr)              # ç´¯ç§¯å’Œ
np.cumprod(arr)             # ç´¯ç§¯ä¹˜ç§¯
np.cummax(arr)              # ç´¯ç§¯æœ€å¤§å€¼
np.cummin(arr)              # ç´¯ç§¯æœ€å°å€¼
np.diff(arr)                # å·®åˆ†
np.gradient(arr)            # æ¢¯åº¦

# ======================================
# ğŸ”„ æ’åºå’Œæœç´¢
# ======================================
np.sort(arr)                # æ’åº
np.argsort(arr)             # æ’åºç´¢å¼•
np.searchsorted(arr, 3)     # äºŒåˆ†æœç´¢
np.partition(arr, 2)        # éƒ¨åˆ†æ’åº
np.argmax(arr)              # æœ€å¤§å€¼çš„ç´¢å¼•
np.argmin(arr)              # æœ€å°å€¼çš„ç´¢å¼•

# ======================================
# ğŸ¨ æ•°å­¦å‡½æ•°
# ======================================
np.sin(arr), np.cos(arr), np.tan(arr)  # ä¸‰è§’å‡½æ•°
np.arcsin(arr)              # åä¸‰è§’å‡½æ•°
np.exp(arr), np.log(arr)    # æŒ‡æ•°ã€å¯¹æ•°
np.log10(arr), np.log2(arr) # å¸¸ç”¨å¯¹æ•°
np.power(arr, 2)            # å¹‚è¿ç®—
np.sqrt(arr), np.cbrt(arr)  # å¹³æ–¹æ ¹ã€ç«‹æ–¹æ ¹
np.abs(arr), np.sign(arr)   # ç»å¯¹å€¼ã€ç¬¦å·
np.floor(arr), np.ceil(arr), np.round(arr)  # èˆå…¥

# ======================================
# ğŸµ ä¿¡å·å¤„ç† (np.fft)
# ======================================
np.fft.fft(arr)             # å¿«é€Ÿå‚…é‡Œå¶å˜æ¢
np.fft.ifft(arr)            # é€†FFT
np.fft.fft2(matrix)         # 2D FFT
np.fft.fftfreq(len(arr))    # é¢‘ç‡è½´
np.convolve(arr1, arr2)     # å·ç§¯
np.correlate(arr1, arr2)    # ç›¸å…³

# ======================================
# ğŸ² éšæœºæ•° (np.random)
# ======================================
np.random.rand(5)           # [0,1)å‡åŒ€åˆ†å¸ƒ
np.random.randn(5)          # æ ‡å‡†æ­£æ€åˆ†å¸ƒ
np.random.randint(0, 10, 5) # éšæœºæ•´æ•°
np.random.choice(arr, 3)    # éšæœºé€‰æ‹©
np.random.shuffle(arr)      # éšæœºæ‰“ä¹±
np.random.seed(42)          # è®¾ç½®éšæœºç§å­

# ======================================
# ğŸŒ å¹¿æ’­æœºåˆ¶ï¼ˆè‡ªåŠ¨æ‰©å±•ç»´åº¦ï¼‰
# ======================================
arr + 10                    # æ ‡é‡å¹¿æ’­
arr * np.array([1, 2])      # å‘é‡å¹¿æ’­
matrix * arr                # çŸ©é˜µå¹¿æ’­
np.broadcast(arr1, arr2)    # æŸ¥çœ‹å¹¿æ’­å½¢çŠ¶

# ======================================
# ğŸ”§ å®ç”¨å·¥å…·
# ======================================
np.zeros((3, 3))           # å…¨é›¶æ•°ç»„
np.ones((3, 3))            # å…¨ä¸€æ•°ç»„
np.eye(3)                   # å•ä½çŸ©é˜µ
np.diag([1, 2, 3])         # å¯¹è§’çŸ©é˜µ
np.full((3, 3), 5)         # å¡«å……æ•°ç»„
np.arange(0, 10, 2)         # ç­‰å·®æ•°åˆ—
np.linspace(0, 10, 5)      # ç­‰åˆ†åŒºé—´
np.meshgrid(x, y)          # ç½‘æ ¼
```

#### ğŸ“Š Pandas å¸¸ç”¨å‡½æ•°é€ŸæŸ¥

```python
import pandas as pd

# DataFrame æ“ä½œ
df.head(n)                # æŸ¥çœ‹å‰nè¡Œ
df.tail(n)                # æŸ¥çœ‹ånè¡Œ
df.info()                 # æ•°æ®æ¦‚è§ˆ
df.describe()             # æè¿°æ€§ç»Ÿè®¡
df.shape                  # ç»´åº¦

# æ•°æ®æ¸…æ´—
df.dropna()               # åˆ é™¤ç©ºå€¼
df.fillna(value)          # å¡«å……ç©ºå€¼
df.drop_duplicates()      # å»é‡

# æ•°æ®ç­›é€‰
df[df['åˆ—'] > 50]         # æ¡ä»¶ç­›é€‰
df.loc[row, col]          # æ ‡ç­¾ç´¢å¼•
df.iloc[0:5, 0:3]         # ä½ç½®ç´¢å¼•
df.query('åˆ— > 50')       # æŸ¥è¯¢

# åˆ†ç»„èšåˆ
df.groupby('åˆ—').sum()    # åˆ†ç»„æ±‚å’Œ
df.groupby('åˆ—').agg({'A': 'sum', 'B': 'mean'})  # å¤šåˆ—èšåˆ

# é€è§†è¡¨
df.pivot_table(values='å€¼', index='è¡Œ', columns='åˆ—', aggfunc='sum')

# åˆå¹¶è¿æ¥
pd.concat([df1, df2])     # çºµå‘åˆå¹¶
pd.merge(df1, df2, on='é”®') # æ¨ªå‘è¿æ¥
df.join(df2)              # è¿æ¥
```