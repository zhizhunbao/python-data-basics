# Pythonæ•°æ®å¤„ç†ä¸‰å‰‘å®¢

## åœºæ™¯1ï¼šAPIæ•°æ®äº¤æ¢ä¸è½»é‡å­˜å‚¨

**ä»»åŠ¡ï¼šæ¥æ”¶HTTP APIè¿”å›çš„JSONæ•°æ®å¹¶å¿«é€Ÿå¤„ç†ï¼ˆæ— éœ€å®‰è£…å¤–éƒ¨åº“ï¼‰**

> ğŸ’¡ **Python List/Dict = é€šç”¨å¯¹è±¡å¤„ç†ç¥å™¨ï¼Œä»€ä¹ˆéƒ½èƒ½è£…**  
> å°±åƒç‘å£«å†›åˆ€ï¼Œå¯ä»¥å¤„ç†å­—ç¬¦ä¸²ã€æ•°å­—ã€å­—å…¸ã€åˆ—è¡¨å„ç§æ•°æ®ç±»å‹ï¼Œçµæ´»é€šç”¨ï¼

###  List - Pythonæ ‡å‡†åº“ï¼Œæ— éœ€å®‰è£…ä¾èµ–

```python
import json
# ä»APIæ¥æ”¶JSONæ•°æ®
api_response = '''
[
    {"id": 1, "name": "å¼ ä¸‰", "score": 95},
    {"id": 2, "name": "æå››", "score": 87},
    {"id": 3, "name": "ç‹äº”", "score": 92}
]
'''
students = json.loads(api_response)  # ç›´æ¥è½¬ä¸ºPythonå­—å…¸åˆ—è¡¨

# å¿«é€Ÿç­›é€‰å’Œæ’åº
top_students = [s for s in students if s['score'] >= 90]
sorted_students = sorted(students, key=lambda x: x['score'], reverse=True)

print(f"ä¼˜ç§€å­¦ç”Ÿ: {[s['name'] for s in top_students]}")
# è¾“å‡ºç¤ºä¾‹: ä¼˜ç§€å­¦ç”Ÿ: ['å¼ ä¸‰', 'ç‹äº”']

# âœ… ä¼˜åŠ¿ï¼šé›¶ä¾èµ–ã€å¿«é€Ÿã€åŸç”ŸPythonå¯¹è±¡
# âœ… é€‚åˆï¼šAPIäº¤äº’ã€å¾®æœåŠ¡ã€Dockerå®¹å™¨ã€å†·å¯åŠ¨åœºæ™¯
```

###  Pandas - éœ€è¦é¢å¤–å®‰è£…ï¼Œå¤ªé‡

```python
import pandas as pd
df = pd.DataFrame(json.loads(api_response))
top = df[df['score'] >= 90]
print(top)
# åŠŸèƒ½å¼ºå¤§ï¼Œä½†éœ€è¦å®‰è£…pandasåº“ï¼ˆå‡ åMBï¼‰
# åœ¨åµŒå…¥å¼ç¯å¢ƒã€å®¹å™¨ã€å†·å¯åŠ¨åœºæ™¯ä¸‹æ˜¾å¾—è‡ƒè‚¿
```

###  NumPy - æ— æ³•å¤„ç†JSONå¯¹è±¡

```python
import numpy as np
# NumPyæ²¡æœ‰å­—ç¬¦ä¸²å’Œå­—å…¸æ”¯æŒ
# éœ€è¦å…ˆè½¬æ¢ä¸ºæ•°å€¼æ•°ç»„ï¼Œå¤±å»çµæ´»æ€§
```

**ä¼˜åŠ£è¯„é€‰ï¼š**
- **List**: â­â­â­â­â­ é›¶ä¾èµ–ã€è½»é‡çº§ã€å®Œç¾é€‚é…APIå’Œå¾®æœåŠ¡
- **Pandas**: â­â­â­ åŠŸèƒ½å¼ºå¤§ä½†é‡é‡çº§ï¼Œä¸é€‚åˆè½»é‡åœºæ™¯
- **NumPy**: â­ æ— æ³•å¤„ç†æ··åˆç±»å‹æ•°æ®

---

## åœºæ™¯2ï¼šå¤§è§„æ¨¡æ•°å€¼è®¡ç®—ä¸ç§‘å­¦è¿ç®—

**ä»»åŠ¡ï¼šå¤„ç†è‚¡ç¥¨ä»·æ ¼æ•°æ®ï¼Œè®¡ç®—æ”¶ç›Šç‡ã€æ³¢åŠ¨ç‡ï¼Œå¹¶è¿›è¡ŒçŸ©é˜µè®¡ç®—**

> ğŸ’¡ **NumPy = é«˜æ€§èƒ½æ•°ç»„åº“ï¼Œé¿å…é€å…ƒç´ å¾ªç¯**  
> å°±åƒç”¨â€œæ‰¹é‡æ“ä½œâ€æ›¿ä»£â€œä¸€è¡Œä¸€è¡Œå¤„ç†â€ï¼ŒNumPyåœ¨åº•å±‚ç”¨C/C++åŠ é€Ÿï¼Œæ€§èƒ½æå‡10-100å€ï¼

###  NumPy - å‘é‡åŒ–æ“ä½œï¼Œæ€§èƒ½æ— æ•Œ

```python
import numpy as np

# ä»CSVè¯»å–ä»·æ ¼æ•°æ®ï¼ˆ1000ä¸ªäº¤æ˜“æ—¥ï¼‰
prices = np.array([100 + np.cumsum(np.random.randn(1000) * 0.02)]).flatten()

# è®¡ç®—æ”¶ç›Šç‡
returns = np.diff(prices) / prices[:-1] * 100

# ç»Ÿè®¡è¿ç®— - å‘é‡åŒ–ï¼Œæå¿«
mean_return = np.mean(returns)
volatility = np.std(returns) * np.sqrt(252)  # å¹´åŒ–æ³¢åŠ¨ç‡

# æ‰¹é‡æ¡ä»¶ç­›é€‰
positive_days = returns[returns > 0]
negative_days = returns[returns < 0]

# çŸ©é˜µè¿ç®—ï¼šè®¡ç®—åæ–¹å·®çŸ©é˜µï¼ˆå¤šä¸ªèµ„äº§çš„æ”¶ç›Šç‡ï¼‰
asset_returns = np.random.randn(100, 252)  # 100åªè‚¡ç¥¨ï¼Œ252ä¸ªäº¤æ˜“æ—¥
cov_matrix = np.cov(asset_returns)  # åæ–¹å·®çŸ©é˜µï¼Œæå¿«

print(f"å¹³å‡æ”¶ç›Šç‡: {mean_return:.3f}%")
print(f"å¹´åŒ–æ³¢åŠ¨ç‡: {volatility:.1f}%")
print(f"ä¸Šæ¶¨å¤©æ•°: {len(positive_days)}, ä¸‹è·Œå¤©æ•°: {len(negative_days)}")

# è¾“å‡ºç¤ºä¾‹:
# å¹³å‡æ”¶ç›Šç‡: 0.012%
# å¹´åŒ–æ³¢åŠ¨ç‡: 25.3%
# ä¸Šæ¶¨å¤©æ•°: 508, ä¸‹è·Œå¤©æ•°: 491
```

###  List - æ€§èƒ½ç¾éš¾ï¼Œå†…å­˜çˆ†ç‚¸

```python
# ç”¨Listå¤„ç†ï¼Œéœ€è¦éå†æ•´ä¸ªæ•°ç»„
import csv
prices = []
with open('prices.csv', 'r') as f:
    reader = csv.reader(f)
    for row in reader:
        prices.append(float(row[0]))

# è®¡ç®—æ”¶ç›Šç‡éœ€è¦æ‰‹åŠ¨éå†
returns = []
for i in range(len(prices) - 1):
    returns.append((prices[i+1] - prices[i]) / prices[i] * 100)

# è®¡ç®—å¹³å‡å€¼éœ€è¦å†éå†ä¸€æ¬¡
mean_return = sum(returns) / len(returns)  # è¶…æ…¢ï¼

# çŸ©é˜µè¿ç®—ï¼Ÿä¸å¯èƒ½çš„
```

###  Pandas - ä¸ºè¡¨æ ¼è®¾è®¡çš„ï¼Œå¢åŠ ä¸å¿…è¦çš„å¼€é”€

```python
import pandas as pd
import numpy as np

# Pandasåº•å±‚ä¾èµ–NumPyï¼Œä½†å¢åŠ äº†ç´¢å¼•ã€ç±»å‹ç­‰å¼€é”€
prices = pd.Series(np.random.randn(1000).cumsum())
returns = prices.pct_change() * 100
mean_return = returns.mean()  # æ¯”NumPyæ…¢

# çŸ©é˜µè®¡ç®—æ›´éº»çƒ¦
```

**ä¼˜åŠ£è¯„é€‰ï¼š**
- **NumPy**: â­â­â­â­â­ æ€§èƒ½æœ€ä½³ï¼Œæ•°å­¦è¿ç®—ä¸“ç²¾ï¼Œå‘é‡åŒ–æ“ä½œ
- **List**: â­â­ æ€§èƒ½æå·®ï¼Œéœ€è¦å¤šæ¬¡éå†
- **Pandas**: â­â­ ä¸ºè¡¨æ ¼è®¾è®¡ï¼Œæ•°å€¼è®¡ç®—ä¸å¦‚NumPyå¿«

---

## åœºæ™¯3ï¼šå¤æ‚å•†ä¸šæ•°æ®åˆ†æ

**ä»»åŠ¡ï¼šåˆ†æExcelé”€å”®æ•°æ®ï¼Œæ‰§è¡Œå¤šç»´åº¦åˆ†ç»„ã€é€è§†è¡¨ã€æ—¶é—´åºåˆ—åˆ†æ**

> ğŸ’¡ **Pandas = èƒ½ç¼–ç¨‹çš„Excel + åç«¯çš„SQL**  
> å¦‚æœä½ ç†Ÿæ‚‰Excelçš„æ•°æ®é€è§†è¡¨å’ŒSQLçš„GROUP BYï¼Œé‚£ä¹ˆPandaså°±æ˜¯ä½ çš„èœï¼

###  Pandas - å•†ä¸šåˆ†æç¥å™¨ï¼Œä¸å¯æ›¿ä»£

```python
import pandas as pd
# ä»Excelè¯»å–æ•°æ®
df = pd.DataFrame({
    'æ—¥æœŸ': ['2024-01-01', '2024-01-01', '2024-01-02', '2024-01-02', '2024-01-03'],
    'åœ°åŒº': ['åŒ—äº¬', 'ä¸Šæµ·', 'åŒ—äº¬', 'å¹¿å·', 'ä¸Šæµ·'],
    'é”€å”®é¢': [1000, 1500, 800, 1200, 2000],
    'äº§å“': ['ç¬”è®°æœ¬', 'é¼ æ ‡', 'é”®ç›˜', 'æ˜¾ç¤ºå™¨', 'ç¬”è®°æœ¬']
})

# âœ… å¤šç»´åº¦åˆ†ç»„åˆ†æ
result = df.groupby(['åœ°åŒº', 'äº§å“'])['é”€å”®é¢'].sum()
print("æŒ‰åœ°åŒºå’Œäº§å“åˆ†ç»„ç»Ÿè®¡:")
print(result)

# âœ… é€è§†è¡¨ - List/NumPyå®Œå…¨æ— æ³•å®ç°
pivot = df.pivot_table(values='é”€å”®é¢', index='åœ°åŒº', columns='äº§å“', aggfunc='sum')
print("\né€è§†è¡¨:")
print(pivot)

# âœ… æ—¶é—´åºåˆ—åˆ†æ
df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'])
daily = df.groupby(df['æ—¥æœŸ'].dt.date)['é”€å”®é¢'].sum()
print("\næ¯æ—¥é”€å”®é¢:")
print(daily)

# è¾“å‡ºç¤ºä¾‹:
# æŒ‰åœ°åŒºå’Œäº§å“åˆ†ç»„ç»Ÿè®¡:
# åœ°åŒº  äº§å“
# å¹¿å·  æ˜¾ç¤ºå™¨    1200
# ä¸Šæµ·  é¼ æ ‡      1500
#      ç¬”è®°æœ¬    2000
# åŒ—äº¬  é”®ç›˜       800
#      ç¬”è®°æœ¬    1000
#
# é€è§†è¡¨:
# äº§å“    ç¬”è®°æœ¬    é”®ç›˜    æ˜¾ç¤ºå™¨    é¼ æ ‡
# åœ°åŒº
# å¹¿å·      NaN   NaN  1200.0    NaN
# ä¸Šæµ·   2000.0   NaN     NaN  1500.0
# åŒ—äº¬   1000.0   800     NaN    NaN
#
# æ¯æ—¥é”€å”®é¢:
# æ—¥æœŸ
# 2024-01-01    2500
# 2024-01-02    2000
# 2024-01-03    2000
```

###  List - æ— æ³•å®ç°é€è§†è¡¨ç­‰é«˜çº§åŠŸèƒ½

```python
sales_data = [
    {'æ—¥æœŸ': '2024-01-01', 'region': 'åŒ—äº¬', 'amount': 1000, 'product': 'ç¬”è®°æœ¬'},
    {'æ—¥æœŸ': '2024-01-01', 'region': 'ä¸Šæµ·', 'amount': 1500, 'product': 'é¼ æ ‡'},
]
# ç®€å•åˆ†ç»„å‹‰å¼ºå¯ä»¥
grouped = {}
for record in sales_data:
    key = (record['region'], record['product'])
    grouped[key] = grouped.get(key, 0) + record['amount']
print(f"åˆ†ç»„ç»“æœ: {grouped}")  
# âŒ é€è§†è¡¨ï¼Ÿæ— æ³•å®ç°
# âŒ æ—¶é—´åºåˆ—ï¼Ÿæ— æ³•å®ç°
# âŒ ç»Ÿè®¡åˆ†æï¼Ÿéœ€è¦æ‰‹å·¥å®ç°
```

###  NumPy - æ²¡æœ‰è¡¨æ ¼å’Œåˆ†ç»„æ¦‚å¿µ

```python
import numpy as np
# NumPyåªèƒ½å¤„ç†åŒè´¨æ•°å€¼æ•°ç»„
# æ²¡æœ‰åˆ†ç»„ã€é€è§†è¡¨ç­‰åŠŸèƒ½
# å®Œå…¨ä¸é€‚åˆå•†ä¸šåˆ†æ
```

**ä¼˜åŠ£è¯„é€‰ï¼š**
- **Pandas**: â­â­â­â­â­ å•†ä¸šåˆ†æç¥å™¨ï¼Œé€è§†è¡¨ã€æ—¶é—´åºåˆ—ä¸å¯æ›¿ä»£
- **List**: â­â­ æ— æ³•å®ç°é€è§†è¡¨ç­‰é«˜çº§åŠŸèƒ½
- **NumPy**: â­ æ²¡æœ‰è¡¨æ ¼åˆ†æèƒ½åŠ›

### å†³ç­–æ ‘é€‰æ‹©

```mermaid
flowchart TD
  A[Pythonæ•°æ®å¤„ç†å·¥å…·é€‰æ‹©] --> B{æ˜¯å¦ä¸ºAPI/å¾®æœåŠ¡/è½»é‡åœºæ™¯}
  B -->|æ˜¯<br/>éœ€è¦é›¶ä¾èµ–| C[List<br/>é›¶ä¾èµ– å¿«é€Ÿ]
  B -->|å¦| D{æ•°æ®ç±»å‹}
  
  D -->|ä¸€è‡´<br/>çº¯æ•°å€¼æ•°ç»„| E{éœ€è¦é«˜æ€§èƒ½è®¡ç®—}
  D -->|ä¸ä¸€è‡´<br/>æ··åˆç±»å‹è¡¨æ ¼| F{éœ€è¦é€è§†è¡¨/åˆ†ç»„}
  
  E -->|æ˜¯<br/>çŸ©é˜µè¿ç®— ç§‘å­¦è®¡ç®—| G[NumPy<br/>å‘é‡åŒ–è¿ç®—]
  E -->|å¦<br/>ç®€å•å¤„ç†| C
  
  F -->|æ˜¯<br/>å•†ä¸šåˆ†æ| H[Pandas<br/>é€è§†è¡¨ æ—¶é—´åºåˆ—]
  F -->|å¦<br/>åŸºç¡€æ“ä½œ| C
  
  style A fill:#e1f5ff
  style C fill:#fff4e1
  style G fill:#ffe1f5
  style H fill:#e1ffe1
```

### ä¸‰å¤§æ¡†æ¶å¸¸ç”¨å‡½æ•°

| åŠŸèƒ½ | Listï¼ˆåŸç”ŸPythonï¼‰ | NumPy | Pandas |
|------|-------------------|-------|--------|
| **æ•°æ®è¯»å–** | `json.loads()` | `np.loadtxt()` | `pd.read_csv()` / `pd.read_excel()` |
| **è¿‡æ»¤ç­›é€‰** | `[x for x in lst if x > 5]` | `arr[arr > 5]` | `df[df['åˆ—'] > 5]` |
| **æ’åº** | `sorted(lst, key=lambda x: x)` | `np.sort(arr)` | `df.sort_values('åˆ—')` |
| **å»é‡** | `list(set(lst))` | `np.unique(arr)` | `df.drop_duplicates()` |
| **ç»Ÿè®¡è®¡ç®—** | `sum(lst)`, `len(lst)` | `np.sum()`, `np.mean()`, `np.std()` | `df.sum()`, `df.mean()`, `df.describe()` |
| **åˆ†ç»„èšåˆ** | æ‰‹åŠ¨å¾ªç¯ | âŒ æ—  | `df.groupby().agg()` |
| **é€è§†è¡¨** | âŒ æ— æ³•å®ç° | âŒ æ— æ³•å®ç° | `df.pivot_table()` |
| **æ—¶é—´åºåˆ—** | âŒ æ— æ³•å®ç° | `np.datetime64` | `pd.to_datetime()`, `resample()` |
| **æ¡ä»¶æ›´æ–°** | æ‰‹åŠ¨å¾ªç¯ | `np.where(condition, x, y)` | `df.loc[condition, 'åˆ—'] = value` |
| **å­—ç¬¦ä¸²å¤„ç†** | `str.split()`, `str.strip()` | âŒ æ—  | `df['åˆ—'].str.split()` |
| **åˆå¹¶è¿æ¥** | `list1 + list2` | `np.concatenate()` | `pd.concat()`, `pd.merge()` |
| **æ•°æ®é€è§†** | âŒ æ— æ³•å®ç° | âŒ æ— æ³•å®ç° | `df.pivot()` |

#### ğŸ¯ List å¸¸ç”¨å‡½æ•°é€ŸæŸ¥

```python
# åŸºç¡€æ“ä½œ
data = [1, 2, 3, 4, 5]
data.append(6)          # è¿½åŠ 
data.extend([7, 8])      # æ‰©å±•
data.insert(0, 0)        # æ’å…¥
data.pop()               # å¼¹å‡ºæœ€åä¸€ä¸ª

# ç­›é€‰è¿‡æ»¤
filtered = [x for x in data if x > 3]    # æ¡ä»¶ç­›é€‰
mapped = [x * 2 for x in data]           # æ˜ å°„å˜æ¢

# æ’åºå»é‡
sorted_data = sorted(data)               # æ’åº
unique_data = list(set(data))            # å»é‡
```

#### ğŸ”¢ NumPy å¸¸ç”¨å‡½æ•°é€ŸæŸ¥

```python
import numpy as np

arr = np.array([1, 2, 3, 4, 5])

# æ•°ç»„æ“ä½œ
arr.reshape(5, 1)        # é‡å¡‘å½¢çŠ¶ (5è¡Œ1åˆ—)
arr.flatten()            # å±•å¹³
np.concatenate([arr1, arr2])  # æ‹¼æ¥

# ç»Ÿè®¡å‡½æ•°
np.sum(arr)              # æ±‚å’Œ
np.mean(arr)             # å¹³å‡å€¼
np.std(arr)              # æ ‡å‡†å·®
np.median(arr)           # ä¸­ä½æ•°
np.min(arr), np.max(arr) # æœ€å€¼

# æ¡ä»¶æ“ä½œ
np.where(arr > 3, 'high', 'low')  # æ¡ä»¶èµ‹å€¼
arr[arr > 3]                      # å¸ƒå°”ç´¢å¼•

# æ•°å­¦è¿ç®—
np.sin(arr), np.cos(arr)  # ä¸‰è§’å‡½æ•°
np.exp(arr)               # æŒ‡æ•°
np.log(arr)               # å¯¹æ•°
```

#### ğŸ“Š Pandas å¸¸ç”¨å‡½æ•°é€ŸæŸ¥

```python
import pandas as pd

# DataFrame æ“ä½œ
df.head(n)                # æŸ¥çœ‹å‰nè¡Œ
df.tail(n)                # æŸ¥çœ‹ånè¡Œ
df.info()                 # æ•°æ®æ¦‚è§ˆ
df.describe()             # æè¿°æ€§ç»Ÿè®¡
df.shape                  # ç»´åº¦

# æ•°æ®æ¸…æ´—
df.dropna()               # åˆ é™¤ç©ºå€¼
df.fillna(value)          # å¡«å……ç©ºå€¼
df.drop_duplicates()      # å»é‡

# æ•°æ®ç­›é€‰
df[df['åˆ—'] > 50]         # æ¡ä»¶ç­›é€‰
df.loc[row, col]          # æ ‡ç­¾ç´¢å¼•
df.iloc[0:5, 0:3]         # ä½ç½®ç´¢å¼•
df.query('åˆ— > 50')       # æŸ¥è¯¢

# åˆ†ç»„èšåˆ
df.groupby('åˆ—').sum()    # åˆ†ç»„æ±‚å’Œ
df.groupby('åˆ—').agg({'A': 'sum', 'B': 'mean'})  # å¤šåˆ—èšåˆ

# é€è§†è¡¨
df.pivot_table(values='å€¼', index='è¡Œ', columns='åˆ—', aggfunc='sum')

# åˆå¹¶è¿æ¥
pd.concat([df1, df2])     # çºµå‘åˆå¹¶
pd.merge(df1, df2, on='é”®') # æ¨ªå‘è¿æ¥
df.join(df2)              # è¿æ¥
```